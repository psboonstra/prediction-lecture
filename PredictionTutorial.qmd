---
title: "Prediction Models: Tutorial"
author: "Phil Boonstra"
subtitle: "BDSI 2025; University of Michigan"
format: 
  revealjs:
    smaller: true
    scrollable: true
    theme: serif
    self-contained: true
    slide-number: c/t
    footer: "[Main Page](https://psboonstra.github.io/prediction-lecture/)"
editor: source
engine: knitr
---


```{r setup, include=FALSE}
library(tidyverse); 
library(broom);
library(ggrepel);
library(knitr);
library(glue);
library(MASS);
library(tidyverse);
library(broom);
library(RColorBrewer);
library(pROC);
library(logistf);
library(glmnet);
library(glmnetUtils);
library(ggcorrplot);
knitr::opts_chunk$set(echo = T, warning = F, message = F, cache = F, `attr-source` = "style='font-size: 1.2em'", `attr-output` = "style='font-size: 0.75em'");
knitr::knit_hooks$set(mysize = function(before, options, envir) {
  if (before) 
    return(options$size);
})
options(digits = 3);
code_flag = FALSE
```


## Example: Breast Cancer Diagnosis data

Digitized image of fine needle aspirate (FNA) of breast mass from 569 patients 

![](StreetFig2.png){ width=75% }


::: {style="font-size: 75%;"}
Figure 2, Street (1993)
:::


##

*Outcome* Clinical diagnosis (malignant or benign)

*Predictors*

a. radius (mean of distances from center to points on the perimeter)
b. texture (standard deviation of gray-scale values)
c. perimeter
d. area
e. smoothness (local variation in radius lengths)
f. compactness (perimeter^2 / area - 1.0)
g. concavity (severity of concave portions of the contour)
h. concave points (number of concave portions of the contour)
i. symmetry 
j. fractal dimension ("coastline approximation" - 1)


Data include mean, "standard error", and worst measurements. 

About 35% of diagnoses were malignant

```{r}
#| echo: false

breast_dx <-
  read_csv("bdiag.csv", show_col_types = FALSE) %>%
  # Translate M/D into 1/0
  mutate(malignant = 1 * (diagnosis == "M")) %>% 
  # Drop errant space in 'concave points_mean' variable name 
  rename_with(~str_replace(string = ., pattern = " ", replacement = "")) %>%
  # Focus only on worst measurements
  #dplyr::select(malignant, 
  #       contains("_worst")) 
  dplyr::select(-id, -diagnosis)
set.seed(1)
fold_partition <- sample(c(rep(1, 300), rep(2, 135), rep(3, 134)))
training_index <- which(fold_partition == 1);
validation_index <- which(fold_partition == 2);
test_index <- which(fold_partition == 3);
write_csv(breast_dx %>% slice(training_index), file = "breast_dx_train.csv")
write_csv(breast_dx %>% slice(validation_index), file = "breast_dx_validation.csv")
write_csv(breast_dx %>% slice(test_index), file = "breast_dx_test.csv")

```


## 

Task: Build a prediction model to predict probability of being
malignant given cell characteristics.

1. Use the training data ('breast_dx_train.csv') and the validation data ('breast_dx_train.csv') to build and select the model. 

2. You can use logistic regression with any of model building approaches
we considered, or something else. You can alternatively build a classifier using a machine learning approach. Note that if you develop a model that only classifies observations, your MSPE, Absolute, and 0-1 loss will all be the same.

3. Use the training and validation data any way you want, but do not use the test data until you've selected one final model. No cheating and no going back to fiddle with the model after you've seen the test data!

4. Evaluate your one model on the test data ('breast_dx_test.csv') and report your performance metrics here: 

<https://forms.gle/6kmfzTPok25hi4v26>


## Getting started

Original data are available at 
<https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)>

```{r}
#| eval: false
#| echo: true

library(tidyverse) #for read_csv
library(MASS); #stepAIC
library(pROC);#pROC
library(logistf);#logistf
library(glmnet);#glmnet
library(glmnetUtils);#formula interface for glmnet

# 300 randomly selected observations for training
breast_dx_train <- read_csv("https://raw.githubusercontent.com/psboonstra/prediction-lecture/refs/heads/main/breast_dx_train.csv")
# 135 randomly selected observations for validation
breast_dx_validation <- read_csv("https://raw.githubusercontent.com/psboonstra/prediction-lecture/refs/heads/main/breast_dx_validation.csv")
# 134 remaining observations for testing
breast_dx_test <- read_csv("https://raw.githubusercontent.com/psboonstra/prediction-lecture/refs/heads/main/breast_dx_test.csv")

# Build your model...

# Get predictions from your model with: 
test_predictions <-
  predict(my_model, newdata = breast_dx_test, type = "response")
# Get MSPE, Absolute, 0-1 loss, and deviance using code from lecture

# Get AUC
roc(response = breast_dx_test$malignant, 
    predictor = test_predictions)

```

## Results

```{r}
#| eval: !expr code_flag
#| echo: !expr code_flag

library(readxl)
resps <- 
  read_xlsx("BCa Diagnosis (Responses).xlsx") %>%
  mutate(OneMinusAUC = 1 - AUC, .keep = "unused") %>%
  pivot_longer(cols = -Timestamp) %>%
  mutate(value_pretty = formatC(value, format = "f", digits = 3))

ggplot(resps, aes(x = value)) +
  geom_boxplot() +
  geom_point(data = resps %>% group_by(name) %>% filter(value == min(value)), y = 0, color = "red") +
  geom_label_repel(data = resps %>% group_by(name) %>% filter(value == min(value)), 
                   aes(label = value_pretty), y = 0, nudge_y = 0.1, size = 3, direction = "y") +
  facet_wrap(vars(name), scales = "free") +
  scale_y_continuous(breaks = NULL)
  
```


## References

Mangasarian, O.L., Street, W.N. and Wolberg, W.H., 1995. Breast cancer diagnosis and prognosis via linear programming. Operations research, 43(4), pp.570-577.

Street, W.N., Wolberg, W.H. and Mangasarian, O.L., 1993, July. Nuclear feature extraction for breast tumor diagnosis. In Biomedical image processing and biomedical visualization (Vol. 1905, pp. 861-870). SPIE.


\scriptsize